# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19z6_KVVDVsSTafj9t1yadvqWBk9NRbdC

**MACHINE LEARNING ASSIGNMENT 3**

Electricity Consumption Prediction
"""

#importing all the required libraries
import numpy as np
import pandas as pd
import sklearn
import scipy

import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

#Load the dataset
train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')

train_df.info()

train_df

test_df.tail()

import datetime as dt
import numpy as np
dt = pd.to_datetime(train_df['datetime']).dt
train_df['year'] = dt.year
train_df['month'] = dt.month
train_df['day'] = dt.day
train_df['time'] = dt.hour

train_df.head()

dt = pd.to_datetime(test_df['datetime']).dt
test_df['year'] = dt.year
test_df['month'] = dt.month
test_df['day'] = dt.day
test_df['time'] = dt.hour

test_df

#Step2:
#ordinal encoder
from sklearn import preprocessing
from sklearn.preprocessing import OrdinalEncoder

enc = OrdinalEncoder()

train_df.var2 = enc.fit_transform(train_df.var2.values.reshape(-1,1))
test_df.var2 = enc.fit_transform(test_df.var2.values.reshape(-1,1))
train_df

#Step 3:
#converting year,month,day,time in train dataset to interger values
train_df.year = train_df.year.astype(int)
train_df.month = train_df.month.astype(int)
train_df.day = train_df.day.astype(int)
train_df.time = train_df.time.astype(int)

#converting year,month,day,time in test dataset to interger values
test_df.year = test_df.year.astype(int)
test_df.month = test_df.month.astype(int)
test_df.day = test_df.day.astype(int)
test_df.time = test_df.time.astype(int)

#Removing columns containing ID ,datetime and electricity consumption and extracting X variables and y separetely
ID = test_df.ID
y = train_df.electricity_consumption.values
X = train_df.drop(['ID', 'datetime', 'electricity_consumption'], axis=1, inplace=False)
X_test = test_df.drop(['ID', 'datetime'], axis=1, inplace=False)

#Dividing dataset into test and val
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=1,shuffle=False)
X_train.shape, X_val.shape, y_train.shape, y_val.shape,X_test.shape

"""MODEL1:RANDOM FOREST REGRESSION"""

#Intializing and fitting the Random Forest Regressor model                      
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor

model1 = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=1000, random_state=1)).fit(X_train,y_train)
print(model1.score(X_train, y_train))

#Performing prediction and printing the metric score

y_pred = model1.predict(X_val)
y_pred1=model1.predict(X_train)
print(model1.score(X_val, y_val))

#Evaluating the mean squared error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error as mae
from math import sqrt

rms = sqrt(mean_squared_error(y_val, y_pred)) 
print("rms1:",rms)
rms1 = sqrt(mean_squared_error(y_train, y_pred1)) 
print("rms2:",rms1)
error = mae(y_val, y_pred)
print("mae:" ,error)
rscore=r2_score(y_val, y_pred) 
print("R2_score:",rscore)

import numpy as np
plt.figure()
plt.plot(y_val, y_pred, '+', MarkerEdgeColor='m', MarkerFaceColor = 'w', markersize = 12 )
plt.title('Random Forest Model')
plt.xlabel('Actual  values')
plt.ylabel('Predicted  values')
plt.plot(np.unique(y_val), np.poly1d(np.polyfit(y_val, y_pred, 1))(np.unique(y_val)), color = 'k')
plt.show()

"""MODEL2:K Nearest Neighbour """

from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler


model2 = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=15)).fit(X_train,y_train)
print(model2.score(X_train, y_train))

y1_pred = model2.predict(X_val)
y2_pred=model2.predict(X_train)
print(model2.score(X_val, y_val))

from sklearn.metrics import mean_squared_error
from math import sqrt

rms = sqrt(mean_squared_error(y_val, y1_pred)) 
print("rms1:",rms)
rms1 = sqrt(mean_squared_error(y_train, y2_pred)) 
print("rms2:",rms1)
error = mae(y_val, y1_pred)
print("mae:" ,error)
rscore=r2_score(y_val, y1_pred) 
print("R2_score:",rscore)

import numpy as np
plt.figure()
plt.plot(y_val, y1_pred, '*', MarkerEdgeColor='c', MarkerFaceColor = 'w', markersize = 12 )
plt.title('KNN Model')
plt.xlabel('Actual  values')
plt.ylabel('Predicted  values')
plt.plot(np.unique(y_val), np.poly1d(np.polyfit(y_val, y1_pred, 1))(np.unique(y_val)), color = 'red')
plt.show()

predicted_table=pd.DataFrame({'Actual': y_val, 'Predicted': y_pred})
predicted_table

plt.plot(y_test, y_pred, '*', MarkerEdgeColor='c', MarkerFaceColor = 'w', markersize = 10 )
plt.title('Support Vector Regression Model')
plt.xlabel('Actual Tensile Strength values')
plt.ylabel('Predicted Tensile Strength values')
plt.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, y_pred, 1))(np.unique(y_test)), color = 'red')
plt.show()

predicted_table1=pd.DataFrame({'Actual': y_val, 'Predicted': y1_pred})
predicted_table1